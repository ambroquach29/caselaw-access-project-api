{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "This is how it looks after being vectorized:\n",
      "\n",
      "TF-IDF Matrix:\n",
      "             ai  available   course   courses  educative  fundamentals  \\\n",
      "Doc 1  0.000000   0.000000  0.57735  0.000000   0.000000       0.57735   \n",
      "Doc 2  0.344315   0.000000  0.00000  0.000000   0.344315       0.00000   \n",
      "Doc 3  0.382743   0.485461  0.00000  0.485461   0.382743       0.00000   \n",
      "Doc 4  0.000000   0.000000  0.00000  0.000000   0.000000       0.00000   \n",
      "\n",
      "       generative  keyboard  learning    online  platform   powered      rag  \\\n",
      "Doc 1    0.000000   0.00000  0.000000  0.000000  0.000000  0.000000  0.57735   \n",
      "Doc 2    0.000000   0.00000  0.436719  0.436719  0.436719  0.436719  0.00000   \n",
      "Doc 3    0.485461   0.00000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
      "Doc 4    0.000000   0.57735  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
      "\n",
      "         using  writing  \n",
      "Doc 1  0.00000  0.00000  \n",
      "Doc 2  0.00000  0.00000  \n",
      "Doc 3  0.00000  0.00000  \n",
      "Doc 4  0.57735  0.57735  \n",
      "NearestNeighbors(metric='cosine', n_neighbors=1)\n",
      "Query Vector for 'What course is this?':\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Nearest document index: 0\n",
      "Distance from query: 0.42264973081037416\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Retrieved document: This is the `Fundamentals of RAG course`\n"
     ]
    }
   ],
   "source": [
    "# Importing the TfidfVectorizer from sklearn to convert text to TF-IDF vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Importing the NearestNeighbors from sklearn to create the nearest neighbor index\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "\n",
    "# List of documents to be processed\n",
    "documents = [\n",
    "    \"This is the `Fundamentals of RAG course`\",\n",
    "    \"Educative is an AI-powered online learning platform\",\n",
    "    \"There are several Generative AI courses available on Educative\",\n",
    "    \"I am writing this using my keyboard\"\n",
    "]\n",
    "\n",
    "# Initializing TfidfVectorizer to remove English stop words\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Transforming the documents into a matrix of TF-IDF features\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Create a DataFrame to display the TF-IDF matrix more readably\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names, index=[f\"Doc {i+1}\" for i in range(len(documents))])\n",
    "\n",
    "# Print the TF-IDF matrix using DataFrame for better formatting\n",
    "print(\"--\" * 50)\n",
    "print(\"This is how it looks after being vectorized:\\n\")\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(df)\n",
    "\n",
    "# Importing NearestNeighbors from sklearn for creating the nearest neighbor index\n",
    "# This module is used to efficiently find the closest vector(s) in high-dimensional space, which is crucial for the retrieval functionality in our RAG system\n",
    "\n",
    "# Initializing NearestNeighbors to create a conceptual vector database (index) for the RAG system\n",
    "# This index, utilizing cosine similarity, functions effectively as the vector database, storing all document vectors and enabling their retrieval based on similarity measures\n",
    "index = NearestNeighbors(n_neighbors=1, metric='cosine').fit(tfidf_matrix)\n",
    "print(index)\n",
    "\n",
    "# Function to query the index with a new document/query\n",
    "def query_index(query):\n",
    "    # Transforming the query into the same TF-IDF vector space as the documents\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    print(f\"Query Vector for '{query}':\")\n",
    "    print(query_vec.toarray())\n",
    "\n",
    "    # Finding the nearest neighbor to the query vector in the index\n",
    "    distance, indices = index.kneighbors(query_vec)\n",
    "    print(\"Nearest document index:\", indices[0][0])\n",
    "    print(\"Distance from query:\", distance[0][0])\n",
    "\n",
    "    return documents[indices[0][0]]\n",
    "\n",
    "\n",
    "# Example query to test the indexing and retrieval system\n",
    "query = \"What course is this?\"\n",
    "result = query_index(query)\n",
    "\n",
    "# Printing the document retrieved as the closest match to the query\n",
    "print(\"--\" * 50)\n",
    "print(\"Retrieved document:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "openai.api_key = '{{OpenAI_API}}'  # Set your OpenAI API key here\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def get_gpt4_embedding(text):\n",
    "    response = openai.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    # Access the embedding directly from the response object\n",
    "    return response.data[0].embedding\n",
    "  \n",
    "# List of example documents to be used in the index\n",
    "documents = [\n",
    "    \"This is the Fundamentals of RAG course.\",\n",
    "    \"Educative is an AI-powered online learning platform.\",\n",
    "    \"There are several Generative AI courses available on Educative.\",\n",
    "    \"I am writing this using my keyboard.\",\n",
    "    \"JavaScript is a good programming language :)\"\n",
    "]\n",
    "\n",
    "# Get embeddings for each document using the get_gpt4_embedding function\n",
    "embeddings = [get_gpt4_embedding(doc) for doc in documents]\n",
    "embeddings = np.array(embeddings)\n",
    "print(\"--\" * 50)\n",
    "print(\"This is how it looks after going through an embedding model:\\n\")\n",
    "print(embeddings)\n",
    "\n",
    "# Fit a NearestNeighbors model on the document embeddings using cosine similarity\n",
    "index = NearestNeighbors(n_neighbors=1, metric='cosine').fit(embeddings)\n",
    "\n",
    "# Function to query the index with a given text query\n",
    "\n",
    "\n",
    "def query_index(query):\n",
    "    query_embedding = get_gpt4_embedding(query)\n",
    "    query_embedding = np.array([query_embedding])\n",
    "    distance, indices = index.kneighbors(query_embedding)\n",
    "    return documents[indices[0][0]]\n",
    "\n",
    "# Example Query\n",
    "query = \"What is JS?\"\n",
    "print(\"Query:\", query)\n",
    "result = query_index(query)  # Retrieve the most similar document to the query\n",
    "\n",
    "print(\"Retrieved document:\", result)  # Print the retrieved document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
